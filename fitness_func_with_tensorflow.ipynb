{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation (in Matrix-Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents (NNs) are given bird persepective images of his square shaped world.\n",
    "Their Action Space contains the Options staying, or moving (right, left, up, down).\n",
    "Mit Hilfe von Linarer Algrebrah wird, dem output des Agents entsprechend, ein Foto ihrer Welt im nächsten Simulations-Schritt berechnet.\n",
    "Nach S Simulations-Schritten wird die Position des Agents der Fitness Function übergeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimentions of the world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, W = 4, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_model(L, W):\n",
    "\n",
    "    A = layers.Input(shape=(L,W,2))\n",
    "    h = layers.Flatten()(A)\n",
    "    h = layers.Dense(\n",
    "        4, \n",
    "        activation='sigmoid',\n",
    "        bias_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    )(h)\n",
    "    # h = tf.linalg.normalize(h)\n",
    "    # h = layers.LayerNormalization()(h)  \n",
    "    h = tf.math.divide(\n",
    "        tf.math.subtract(\n",
    "            h, \n",
    "            tf.reduce_min(h)\n",
    "        ), \n",
    "        tf.math.subtract(\n",
    "            tf.reduce_max(h), \n",
    "            tf.reduce_min(h)\n",
    "        )\n",
    "    )\n",
    "    motion = tf.math.round(h, name='agents_motion')\n",
    "\n",
    "    return tf.keras.Model(A, motion, name='agent_nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import shape\n",
    "\n",
    "\n",
    "def get_enviroment_model(A, M, K):\n",
    "\n",
    "    # New Position Vektor K acording to motion M\n",
    "\n",
    "    # M_1 = tf.math.scalar_mul(\n",
    "    #         scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[1,0,0,0]], dtype=tf.float32))),\n",
    "    #         x=tf.constant([[-1,0]], dtype=tf.float32),\n",
    "    #         name='coord. step up'\n",
    "    #     )\n",
    "\n",
    "    # M_2 = tf.math.scalar_mul(\n",
    "    #         scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,1,0,0]], dtype=tf.float32))),\n",
    "    #         x=tf.constant([[1,0]], dtype=tf.float32),\n",
    "    #         name='coord. step down'\n",
    "    #     )\n",
    "\n",
    "    # M_3 = tf.math.scalar_mul(\n",
    "    #         scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,1,0]], dtype=tf.float32))),\n",
    "    #         x=tf.constant([[0,-1]], dtype=tf.float32),\n",
    "    #         name='coord. step left'\n",
    "    #     )\n",
    "\n",
    "    # M_4 = tf.math.scalar_mul(\n",
    "    #         scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,0,1]], dtype=tf.float32))),\n",
    "    #         x=tf.constant([[0,1]], dtype=tf.float32),\n",
    "    #         name='coord. step right'\n",
    "    #     )\n",
    "\n",
    "    # M_12 = tf.math.add(M_1, M_2)\n",
    "    # M_34 = tf.math.add(M_3, M_4)\n",
    "    # M_all = tf.math.add(M_12, M_34)\n",
    "    # K_new = tf.math.add(K, M_all)\n",
    "    \n",
    "    K_new = layers.Dense(units=2)(K)\n",
    "\n",
    "\n",
    "\n",
    "    # # New image B according to motion M\n",
    "\n",
    "    # kernel = np.zeros(shape=(3,3,2,2))\n",
    "    # kernel[1,1,1,1] = 1                     # The convolution on the target dimention in the enviroment's image is the identity\n",
    "\n",
    "\n",
    "    # '''Up'''\n",
    "    # conv_layer_up = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    # conv_layer_up_output = conv_layer_up(A)\n",
    "    \n",
    "    # kernel_up = kernel.copy()\n",
    "    # kernel_up[2,1,0,0] = 1 \n",
    "    # conv_layer_up.set_weights([tf.constant(kernel_up, dtype=tf.float32), tf.constant(0, shape=(2))])                                  \n",
    "\n",
    "    # A_1 = tf.math.scalar_mul(\n",
    "    #     scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[1,0,0,0]], dtype=tf.float32))),\n",
    "    #     x=conv_layer_up_output, \n",
    "    #     name='image_step_up_multi'\n",
    "    # )\n",
    "    # A_1 = tf.math.add(A_1, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[1,0,0,0]], dtype=tf.float32))), x=A), name='image_step_up_add')\n",
    "\n",
    "    # '''Down'''\n",
    "    # conv_layer_down = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    # conv_layer_down_output = conv_layer_down(A_1)\n",
    "    \n",
    "    # kernel_down = kernel.copy()\n",
    "    # kernel_down[0,1,0,0] = 1 \n",
    "    # conv_layer_down.set_weights([tf.constant(kernel_down, dtype=tf.float32), tf.constant(0, shape=(2))])\n",
    "\n",
    "    # A_2 = tf.math.scalar_mul(\n",
    "    #     scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,1,0,0]], dtype=tf.float32))),\n",
    "    #     x=conv_layer_down_output\n",
    "    # )\n",
    "    # A_2 = tf.math.add(A_2, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,1,0,0]], dtype=tf.float32))), x=A_1))\n",
    "\n",
    "    # '''Left'''\n",
    "    # conv_layer_left = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    # conv_layer_left_output = conv_layer_left(A_2)\n",
    "    \n",
    "    # kernel_left = kernel.copy()\n",
    "    # kernel_left[1,2,0,0] = 1 \n",
    "    # conv_layer_left.set_weights([tf.constant(kernel_left, dtype=tf.float32), tf.constant(0, shape=(2))])\n",
    "\n",
    "    # A_3 = tf.math.scalar_mul(\n",
    "    #     scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,1,0]], dtype=tf.float32))),\n",
    "    #     x=conv_layer_left_output\n",
    "    # )\n",
    "    # A_3 = tf.math.add(A_3, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,1,0]], dtype=tf.float32))), x=A_2))\n",
    "\n",
    "    # '''Right'''\n",
    "    # conv_layer_right = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    # conv_layer_right_output = conv_layer_right(A_3)\n",
    "    \n",
    "    # kernel_right = kernel.copy()\n",
    "    # kernel_right[1,0,0,0] = 1 \n",
    "    # conv_layer_right.set_weights([tf.constant(kernel_right, dtype=tf.float32), tf.constant(0, shape=(2))])\n",
    "\n",
    "    # A_4 = tf.math.scalar_mul(\n",
    "    #     scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,0,1]], dtype=tf.float32))),\n",
    "    #     x=conv_layer_right_output\n",
    "    # )\n",
    "    # A_new = tf.math.add(A_4, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,0,1]], dtype=tf.float32))), x=A_3))\n",
    "   \n",
    "    A_new = layers.Flatten()(A)\n",
    "    A_new = layers.concatenate([A_new, M])\n",
    "    A_new = layers.Dense(units=L*W*2)(A_new)\n",
    "    A_new = layers.Reshape(target_shape=(L, W, 2))(A_new)\n",
    "    \n",
    "\n",
    "    # A_new = A + tf.scalar_mul(layers.Dense(1)(M), np.ones(shape=(L,W,2), dtype=np.float32))  \n",
    "    \n",
    "\n",
    "    # return tf.keras.Model((A, M, K), (A_new, K_new), name='Enviroment')\n",
    "    return tf.keras.Model((A, M, K), (K_new), name='Enviroment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function (in Matrix-Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtration der Target-Position von den x,y Koordianten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_num = 4\n",
    "A = layers.Input(shape=(2, pop_num))\n",
    "A_sqr = tf.math.multiply(A, A)\n",
    "\n",
    "A_split_x = tf.split(A_sqr, 2, axis=1, name='split')[0]\n",
    "A_split_y = tf.split(A_sqr, 2, axis=1, name='split')[1]\n",
    "\n",
    "A_sum = tf.math.add(A_split_x, A_split_y)\n",
    "A_norm = tf.linalg.normalize(A_sum)\n",
    "\n",
    "# A_slice_a = tf.slice(A_sqr, [0,0,0], [1,2,1], name=None) \n",
    "# A_slice_b = tf.slice(A_sqr, [0,1,0], [1,2,1], name=None) \n",
    "# A_ave = layers.AveragePooling2D(pool_size=(2))(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0.23695184, 0.3645413 , 0.5285849 , 0.7290826 ]]], dtype=float32), array([[[109.72694]]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "fitness_function = tf.keras.Model(A, A_norm)\n",
    "\n",
    "print(fitness_function.predict(tf.constant([[[1,2,3,4],[5,6,7,8]]])))\n",
    "\n",
    "# Das Netzwert berechnet die Abstandsnorm der x,y Koordinaten zum ursprung.\n",
    "# Für die Nutzung als Fitness Function ist der Output des Models normiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduktion (in Matrix-Representation - Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(generations):\n",
    "    fitness_function(final)\n",
    "\n",
    "    final_coordinates = experience(population)               # Array contains final coordinates of all agents in the population (2 x P)\n",
    "    fitness_function(final_coordinates)\n",
    "\n",
    "    # The 50'th best (closest) agents get to repopulate and cross mutate\n",
    "    # Mutation: Addition of random tensors and agent's model's weights\n",
    "    # Crossmutation: Split tensors of model's weights and concat slices of two different agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we could implement the selection and reproduction process as an optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anstonsten könnte man den Selectionsprozess wie folgt implementieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_50_best_agents = None\n",
    "list_of_50_best_agents = .shuffel(list_of_50_best_agents)\n",
    "\n",
    "\n",
    "old_agent = list_of_50_best_agents[-1]\n",
    "for agent in list_of_50_best_agents[:-2]:\n",
    "    # split agent.model.weights and concatanate with old_agent.\n",
    "    # Create both combinations.\n",
    "    \n",
    "    old_agent.model = None\n",
    "    agent.model = None\n",
    "\n",
    "    old_agent = agent\n",
    "\n",
    "new_agents = [list_of_50_best_agents] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2:\n",
    "\n",
    "Geringere Anzahl an Generations dafür aber Training der Agents mit tf.keras.Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experience_model_original(agent_model, L, W, simulation_steps=10):\n",
    "    \n",
    "    \n",
    "\n",
    "    A = layers.Input(shape=(L,W,2), name='image_enviroment')\n",
    "    K = layers.Input(shape=2, name='agent_position')\n",
    "\n",
    "    enviroment = get_enviroment_model(A, agent_model.output, K)\n",
    "    enviroment.trainable = False\n",
    "\n",
    "    agent_motion = agent_model(A)\n",
    "    (A_new, K_new) = enviroment((A, agent_motion, K))\n",
    "\n",
    "    for experience in range(simulation_steps - 1):\n",
    "        agent_motion = agent_model(A_new)\n",
    "        (A_new, K_new) = enviroment((A_new, agent_motion, K_new))\n",
    "\n",
    "    model_experience = tf.keras.Model((A, K), (K_new), name='one_experience')\n",
    "\n",
    "    # T = layers.Input(shape=2, name='target_position')\n",
    "    # model_experience.add_loss(tf.keras.losses.mse(K_new, T))\n",
    "    \n",
    "    return model_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experience_model(agent_model, L, W, simulation_steps=10):\n",
    "    \n",
    "    A = layers.Input(shape=(L,W,2), name='image_enviroment')\n",
    "    K = layers.Input(shape=2, name='agent_position')\n",
    "    M = layers.Input(shape=4, name='agents_motion')\n",
    "\n",
    "    # enviroment = get_enviroment_model(A, M, K)\n",
    "    # enviroment.trainable = False\n",
    "\n",
    "    dense1 = layers.Dense(units=L*W*2)\n",
    "    dense2 = layers.Dense(units=2)\n",
    "\n",
    "    M = agent_model(A)\n",
    "    A_new = layers.Flatten()(A)\n",
    "    A_new = layers.Concatenate()([A_new, M])\n",
    "    A_new = dense1(A_new)\n",
    "    A_new = layers.Reshape(target_shape=(L, W, 2))(A_new)\n",
    "    K_new = dense2(K)\n",
    "\n",
    "    # K_new = enviroment((A, M, K))\n",
    "\n",
    "    # for experience in range(simulation_steps - 2):\n",
    "    #     M = agent_model(A_new)\n",
    "    #     A_new = layers.Flatten()(A_new)\n",
    "    #     A_new = layers.Concatenate()([A_new, M])\n",
    "    #     A_new = dense1(A_new)\n",
    "    #     A_new = layers.Reshape(target_shape=(L, W, 2))(A_new)\n",
    "    #     K_new = dense2(K_new)\n",
    "        \n",
    "    #     # (A_new, K_new) = enviroment((A_new, agent_motion, K_new))\n",
    "\n",
    "    model_experience = tf.keras.Model((A, K), (K_new), name='one_experience')\n",
    "    \n",
    "    return model_experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate trainng and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enviroment_image(agent_pos, target_pos, raw_image):\n",
    "    raw_image[agent_pos[0], agent_pos[1], 0] = 1          # Place the agent in the image of the enviroment\n",
    "    raw_image[target_pos[0], target_pos[1], 1] = 1        # Place the target in the image of the enviroment\n",
    "    return raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "validation_split=0.7\n",
    "\n",
    "train_size = int(data_size * validation_split)\n",
    "val_size = data_size - train_size\n",
    "\n",
    "agent_positions = np.array([np.random.randint(size=train_size, low=0, high=L),\n",
    "                        np.random.randint(size=train_size, low=0, high=W)]).reshape((train_size, 2))\n",
    "val_agent_positions = np.array([np.random.randint(size=val_size, low=0, high=L),\n",
    "                        np.random.randint(size=val_size, low=0, high=W)]).reshape((val_size, 2))                            \n",
    "\n",
    "target_positions = np.array([np.random.randint(size=train_size, low=0, high=L),\n",
    "                        np.random.randint(size=train_size, low=0, high=W)]).reshape((train_size, 2))\n",
    "val_target_positions = np.array([np.random.randint(size=val_size, low=0, high=L),\n",
    "                        np.random.randint(size=val_size, low=0, high=W)]).reshape((val_size, 2))\n",
    "\n",
    "raw_image = np.zeros(shape=(L,W,2))\n",
    "train_images = np.array([get_enviroment_image(agent_positions[i], target_positions[i], raw_image) for i in range(train_size)])\n",
    "val_images = np.array([get_enviroment_image(val_agent_positions[i], val_target_positions[i], raw_image) for i in range(val_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generator Approach: (Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_enviroment_image(agent_pos, target_pos, raw_image):\n",
    "#     raw_image[agent_pos[0], agent_pos[1], 0] = 1          # Place the agent in the image of the enviroment\n",
    "#     raw_image[target_pos[0], target_pos[1], 1] = 1        # Place the target in the image of the enviroment\n",
    "#     return tf.constant([raw_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset_generator(data_size, raw_image):\n",
    "#     for i in range(data_size):\n",
    "#         agent_pos = [np.random.randint(low=0, high=L),\n",
    "#                     np.random.randint(low=0, high=W)]\n",
    "#         target_pos = [np.random.randint(low=0, high=L),\n",
    "#                     np.random.randint(low=0, high=W)]\n",
    "\n",
    "#         image = get_enviroment_image(agent_pos=agent_pos, target_pos=target_pos,\n",
    "#                                         raw_image=raw_image.copy())\n",
    "#         # yield (tf.Tensor(image), tf.Tensor(agent_pos), tf.Tensor(target_pos))\n",
    "#         yield ((image, tf.constant(agent_pos, dtype=tf.int32), tf.constant(target_pos, dtype=tf.int32)), (tf.constant(target_pos, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = np.zeros(shape=(L,W,2))\n",
    "# dataset_generator = get_dataset_generator(1000, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tf.data.Dataset approach: (Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_generator = get_dataset_generator(1000, image)\n",
    "from unicodedata import name\n",
    "\n",
    "\n",
    "# dataset = tf.data.Dataset.from_generator(get_dataset_generator,\n",
    "#         output_signature=(\n",
    "#             tf.TensorSpec(shape=(L,W,2)),\n",
    "#             tf.TensorSpec(shape=(2)),\n",
    "#             tf.TensorSpec(shape=(2))\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 0s/step - loss: 2.3555 - mse: 2.3555 - acc: 0.4900\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 800us/step - loss: 1.5527 - mse: 1.5527 - acc: 0.4429\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 800us/step - loss: 1.4341 - mse: 1.4341 - acc: 0.4414\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 800us/step - loss: 1.3619 - mse: 1.3619 - acc: 0.5100\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3183 - mse: 1.3183 - acc: 0.4629\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 800us/step - loss: 1.3038 - mse: 1.3038 - acc: 0.4300\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 810us/step - loss: 1.2815 - mse: 1.2815 - acc: 0.5157\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2632 - mse: 1.2632 - acc: 0.4586\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 800us/step - loss: 1.2528 - mse: 1.2528 - acc: 0.5014\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2536 - mse: 1.2536 - acc: 0.5886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4cccf1250>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_nn = get_agent_model(L, W)\n",
    "model_experience = get_experience_model(agent_nn, L, W, simulation_steps=5)\n",
    "\n",
    "\n",
    "model_experience.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "                        loss=['mse', 'mse'],\n",
    "                        metrics=['mse', 'acc'])\n",
    "\n",
    "model_experience.fit(x=(train_images, agent_positions), y=target_positions, epochs=10, batch_size=64)\n",
    "\n",
    "# model_experience.fit(x=XXX Generator Input XXX, epochs=5)\n",
    "# model_experience.fit(x=XXX tf.data.Dataset Input XXX epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktionen get_agent_model und get_enviroment_model sollen sich gegenseitig Tensoren übergeben und so mehrfach hintereinander sequenziert ein multiples durchlaufen von action-feedback loops simulieren.\n",
    "Keine Probleme bringt die Einbindung vom Agent's Model in ein größeres tf.keras.Model, welches optimiert werden soll (agents weights sind die einzigen trainierbaren).\n",
    "Wird allerdings die enviroment mit eingebunden so wird ein Fehler ('fehlender gradient') geworfen.\n",
    "\n",
    "\n",
    "Führt zu erfolgreichem Training:\n",
    "*   agent_model gibt M an sequential von dense, reshape und flatten weiter (1 Runde) - tf.keras.Model((A, K), (K_new), name='one_experience')\n",
    "\n",
    "Fürt zum Durchlaufen der Trainingsepochen aber loss/ mse (nicht acc) sind mitunter gleich nan\n",
    "*   agent_model gibt M an sequential von dense, reshape und flatten weiter (N > 1 Runde) - tf.keras.Model((A, K), (K_new), name='one_experience')\n",
    "\n",
    "Wann auch immer ich ein weiteres tf.keras.Model einbinden möchte wird der fehler mit den fehlenden gradienten geschmissen!\n",
    "\n",
    "(\"I know this is closed, but I thought I might mention for the sake of Googler's: most non-linear operations (such as tf.cast) do not provide gradients. \"\n",
    "https://github.com/tensorflow/tensorflow/issues/1511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Training Data:\n",
    "position = np.array([[1,1]])\n",
    "target_position = np.array([[3,3]])\n",
    "\n",
    "image = np.zeros(shape=(L,W,2))\n",
    "image[position[:,0], position[:,1], 0] = 1                      # Place the agent in the image of the enviroment\n",
    "image[target_position[:,0], target_position[:,1], 1] = 1        # Place the target in the image of the enviroment\n",
    "image = tf.constant([image])\n",
    "\n",
    "\n",
    "# Create Model in order to training an agent:\n",
    "agent_nn = get_agent_model(L, W)\n",
    "model_experience = get_experience_model(agent_nn, L, W, 10)\n",
    "# model_experience.predict((image, position, target_position))\n",
    "\n",
    "# print('Before motion:')\n",
    "# print(np.swapaxes(np.squeeze(image), 0, 2))\n",
    "\n",
    "# print('Position:', position)\n",
    "\n",
    "print('\\nAfter motion:')\n",
    "# print(np.squeeze(model_life.predict((image, position))[0]))\n",
    "# print(np.swapaxes(np.squeeze(model_experience.predict((image, position, target_position))[0]), 0, 2))\n",
    "# print('Position:', model_experience.predict((image, position, target_position))[1])\n",
    "\n",
    "\n",
    "print(model_experience.predict((image, position)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def life(agent_model, days_in_life, data_size=1000, validation_split=0.7):\n",
    "    \n",
    "    ''' Generate training and validation data: '''\n",
    "    train_size = int(data_size * validation_split)\n",
    "    val_size = data_size - train_size\n",
    "\n",
    "    agent_positions = np.array([np.random.randint(size=train_size, low=0, high=L),\n",
    "                            np.random.randint(size=train_size, low=0, high=W)]).reshape((train_size, 2))\n",
    "    val_agent_positions = np.array([np.random.randint(size=val_size, low=0, high=L),\n",
    "                            np.random.randint(size=val_size, low=0, high=W)]).reshape((val_size, 2))                            \n",
    "\n",
    "    target_positions = np.array([np.random.randint(size=train_size, low=0, high=L),\n",
    "                            np.random.randint(size=train_size, low=0, high=W)]).reshape((train_size, 2))\n",
    "    val_target_positions = np.array([np.random.randint(size=val_size, low=0, high=L),\n",
    "                            np.random.randint(size=val_size, low=0, high=W)]).reshape((val_size, 2))                            \n",
    "\n",
    "    image = np.zeros(shape=(L,W,2))\n",
    "    def get_enviroment_image(agent_pos, target_pos, raw_image):\n",
    "        raw_image[agent_pos[0], agent_pos[1], 0] = 1          # Place the agent in the image of the enviroment\n",
    "        raw_image[target_pos[0], target_pos[1], 1] = 1        # Place the target in the image of the enviroment\n",
    "        return tf.constant([raw_image])\n",
    "\n",
    "    images = [get_enviroment_image(agent_pos=random_agent_positions[i],\n",
    "        target_pos=target_pos,\n",
    "        raw_image=image.copy()) for i, target_pos in enumerate(random_target_positions)]\n",
    "    val_images = [get_enviroment_image(\n",
    "        agent_pos=val_random_agent_positions[i], \n",
    "        target_pos=val_target_pos, \n",
    "        raw_image=image.copy()) for i, val_target_pos in enumerate(val_random_target_positions)]\n",
    "\n",
    "\n",
    "    ''' Create, compile, and train model: '''\n",
    "    model_experience = get_experience_model(agent_model)\n",
    "    \n",
    "    model_experience.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1))\n",
    "\n",
    "    model_experience.fit(random_target_positions, random_target_positions, epochs=days_in_life)\n",
    "    \n",
    "    # return model_life.evaluate(test_random_target_positions)[index_of_the_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# life(agent_nn, days_in_life=5, training_data_size=1000, validation_split=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(generations):\n",
    "#     # Train for T epochs corresponding to the experience of one life-time\n",
    "    \n",
    "#     for i, agent in population.agents:\n",
    "#         fitness_scores[i] = life(agent, days_in_life=days_in_life)\n",
    "\n",
    "\n",
    "#     # The 50'th best (closest) agents get to repopulate and cross mutate\n",
    "#     # Crossmutation: Split tensors of model's weights and concat slices of two different agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('evo_comp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "293cb0476db60aaab2e1b1ba9b26f5f15c0ffb3fa3e660addecd3d738cf07a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
