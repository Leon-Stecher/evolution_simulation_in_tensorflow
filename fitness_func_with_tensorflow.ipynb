{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation (in Matrix-Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents (NNs) are given bird persepective images of his square shaped world.\n",
    "Their Action Space contains the Options staying, or moving (right, left, up, down).\n",
    "Mit Hilfe von Linarer Algrebrah wird, dem output des Agents entsprechend, ein Foto ihrer Welt im nächsten Simulations-Schritt berechnet.\n",
    "Nach S Simulations-Schritten wird die Position des Agents der Fitness Function übergeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimentions of the world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, W = 10, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_model():\n",
    "\n",
    "    A = layers.Input(shape=(L,W,2))\n",
    "    h = layers.Flatten()(A)\n",
    "    h = layers.Dense(\n",
    "        4, \n",
    "        activation='sigmoid',\n",
    "        bias_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    )(h)\n",
    "    # h = tf.linalg.normalize(h)\n",
    "    # h = layers.LayerNormalization()(h)  \n",
    "    h = tf.math.divide(\n",
    "        tf.math.subtract(\n",
    "            h, \n",
    "            tf.reduce_min(h)\n",
    "        ), \n",
    "        tf.math.subtract(\n",
    "            tf.reduce_max(h), \n",
    "            tf.reduce_min(h)\n",
    "        )\n",
    "    )\n",
    "    motion = tf.math.round(h)\n",
    "\n",
    "    return tf.keras.Model(A, motion, name='agent_nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enviroment_model(A, M, K):\n",
    "\n",
    "    # New Position Vektor K acording to motion M\n",
    "\n",
    "    M_1 = tf.math.scalar_mul(\n",
    "            scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[1,0,0,0]], dtype=tf.float32))),\n",
    "            x=tf.constant([[-1,0]], dtype=tf.float32),\n",
    "            name='coord. step up'\n",
    "        )\n",
    "\n",
    "    M_2 = tf.math.scalar_mul(\n",
    "            scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,1,0,0]], dtype=tf.float32))),\n",
    "            x=tf.constant([[1,0]], dtype=tf.float32),\n",
    "            name='coord. step down'\n",
    "        )\n",
    "\n",
    "    M_3 = tf.math.scalar_mul(\n",
    "            scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,1,0]], dtype=tf.float32))),\n",
    "            x=tf.constant([[0,-1]], dtype=tf.float32),\n",
    "            name='coord. step left'\n",
    "        )\n",
    "\n",
    "    M_4 = tf.math.scalar_mul(\n",
    "            scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,0,1]], dtype=tf.float32))),\n",
    "            x=tf.constant([[0,1]], dtype=tf.float32),\n",
    "            name='coord. step right'\n",
    "        )\n",
    "\n",
    "    M_12 = tf.math.add(M_1, M_2)\n",
    "    M_34 = tf.math.add(M_3, M_4)\n",
    "    M_all = tf.math.add(M_12, M_34)\n",
    "    K_new = tf.math.add(K, M_all)\n",
    "\n",
    "\n",
    "\n",
    "    # New image B according to motion M\n",
    "\n",
    "    kernel = np.zeros(shape=(3,3,2,2))\n",
    "    kernel[1,1,1,1] = 1                     # The convolution on the target dimention in the enviroment's image is the identity\n",
    "\n",
    "\n",
    "    '''Up'''\n",
    "    conv_layer_up = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    conv_layer_up_output = conv_layer_up(A)\n",
    "    \n",
    "    kernel_up = kernel.copy()\n",
    "    kernel_up[2,1,0,0] = 1 \n",
    "    conv_layer_up.set_weights([tf.constant(kernel_up, dtype=tf.float32), tf.constant(0, shape=(2))])                                  \n",
    "\n",
    "    A_1 = tf.math.scalar_mul(\n",
    "        scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[1,0,0,0]], dtype=tf.float32))),\n",
    "        x=conv_layer_up_output, \n",
    "        name='image_step_up_multi'\n",
    "    )\n",
    "    A_1 = tf.math.add(A_1, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[1,0,0,0]], dtype=tf.float32))), x=A), name='image_step_up_add')\n",
    "\n",
    "    '''Down'''\n",
    "    conv_layer_down = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    conv_layer_down_output = conv_layer_down(A_1)\n",
    "    \n",
    "    kernel_down = kernel.copy()\n",
    "    kernel_down[0,1,0,0] = 1 \n",
    "    conv_layer_down.set_weights([tf.constant(kernel_down, dtype=tf.float32), tf.constant(0, shape=(2))])\n",
    "\n",
    "    A_2 = tf.math.scalar_mul(\n",
    "        scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,1,0,0]], dtype=tf.float32))),\n",
    "        x=conv_layer_down_output\n",
    "    )\n",
    "    A_2 = tf.math.add(A_2, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,1,0,0]], dtype=tf.float32))), x=A_1))\n",
    "\n",
    "    '''Left'''\n",
    "    conv_layer_left = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    conv_layer_left_output = conv_layer_left(A_2)\n",
    "    \n",
    "    kernel_left = kernel.copy()\n",
    "    kernel_left[1,2,0,0] = 1 \n",
    "    conv_layer_left.set_weights([tf.constant(kernel_left, dtype=tf.float32), tf.constant(0, shape=(2))])\n",
    "\n",
    "    A_3 = tf.math.scalar_mul(\n",
    "        scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,1,0]], dtype=tf.float32))),\n",
    "        x=conv_layer_left_output\n",
    "    )\n",
    "    A_3 = tf.math.add(A_3, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,1,0]], dtype=tf.float32))), x=A_2))\n",
    "\n",
    "    '''Right'''\n",
    "    conv_layer_right = layers.Conv2D(filters=2, kernel_size=(3,3), padding='same', kernel_initializer=tf.constant_initializer(1.))\n",
    "    conv_layer_right_output = conv_layer_right(A_3)\n",
    "    \n",
    "    kernel_right = kernel.copy()\n",
    "    kernel_right[1,0,0,0] = 1 \n",
    "    conv_layer_right.set_weights([tf.constant(kernel_right, dtype=tf.float32), tf.constant(0, shape=(2))])\n",
    "\n",
    "    A_4 = tf.math.scalar_mul(\n",
    "        scalar=tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,0,1]], dtype=tf.float32))),\n",
    "        x=conv_layer_right_output\n",
    "    )\n",
    "    A_new = tf.math.add(A_4, tf.math.scalar_mul(scalar=1 - tf.reduce_sum(tf.math.multiply(M, tf.constant([[0,0,0,1]], dtype=tf.float32))), x=A_3))\n",
    "\n",
    "    return tf.keras.Model((A, M, K), (A_new, K_new), name='Enviroment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function (in Matrix-Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtration der Target-Position von den x,y Koordianten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_num = 4\n",
    "A = layers.Input(shape=(2, pop_num))\n",
    "A_sqr = tf.math.multiply(A, A)\n",
    "\n",
    "A_split_x = tf.split(A_sqr, 2, axis=1, name='split')[0]\n",
    "A_split_y = tf.split(A_sqr, 2, axis=1, name='split')[1]\n",
    "\n",
    "A_sum = tf.math.add(A_split_x, A_split_y)\n",
    "A_norm = tf.linalg.normalize(A_sum)\n",
    "\n",
    "# A_slice_a = tf.slice(A_sqr, [0,0,0], [1,2,1], name=None) \n",
    "# A_slice_b = tf.slice(A_sqr, [0,1,0], [1,2,1], name=None) \n",
    "# A_ave = layers.AveragePooling2D(pool_size=(2))(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0.23695184, 0.3645413 , 0.5285849 , 0.7290826 ]]], dtype=float32), array([[[109.72694]]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "fitness_function = tf.keras.Model(A, A_norm)\n",
    "\n",
    "print(fitness_function.predict(tf.constant([[[1,2,3,4],[5,6,7,8]]])))\n",
    "\n",
    "# Das Netzwert berechnet die Abstandsnorm der x,y Koordinaten zum ursprung.\n",
    "# Für die Nutzung als Fitness Function ist der Output des Models normiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduktion (in Matrix-Representation - Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(generations):\n",
    "    fitness_function(final)\n",
    "\n",
    "    final_coordinates = experience(population)               # Array contains final coordinates of all agents in the population (2 x P)\n",
    "    fitness_function(final_coordinates)\n",
    "\n",
    "    # The 50'th best (closest) agents get to repopulate and cross mutate\n",
    "    # Mutation: Addition of random tensors and agent's model's weights\n",
    "    # Crossmutation: Split tensors of model's weights and concat slices of two different agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we could implement the selection and reproduction process as an optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anstonsten könnte man den Selectionsprozess wie folgt implementieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_50_best_agents = None\n",
    "list_of_50_best_agents = .shuffel(list_of_50_best_agents)\n",
    "\n",
    "\n",
    "old_agent = list_of_50_best_agents[-1]\n",
    "for agent in list_of_50_best_agents[:-2]:\n",
    "    # split agent.model.weights and concatanate with old_agent.\n",
    "    # Create both combinations.\n",
    "    \n",
    "    old_agent.model = None\n",
    "    agent.model = None\n",
    "\n",
    "    old_agent = agent\n",
    "\n",
    "new_agents = [list_of_50_best_agents] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2:\n",
    "\n",
    "Geringere Anzahl an Generations dafür aber Training der Agents mit tf.keras.Model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kann ich als loss den mse von den target koordinaten und der letzten position des agents nehmen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_life_model(agent_model, simulation_steps=10):\n",
    "    \n",
    "    # model_life = tf.keras.Sequential()\n",
    "\n",
    "    A = layers.Input(shape=(L,W,2), name='image_enviroment')\n",
    "    K = layers.Input(shape=2, name='agent_position')\n",
    "\n",
    "    enviroment = get_enviroment_model(A, agent_model.output, K)\n",
    "    enviroment.trainable = False\n",
    "\n",
    "    agent_motions = []\n",
    "\n",
    "    agent_motion = agent_model(A)\n",
    "    agent_motions.append(agent_motion)\n",
    "    (A_new, K_new) = enviroment((A, agent_motion, K))\n",
    "\n",
    "    for experience in range(simulation_steps - 1):\n",
    "        agent_motion = agent_model(A_new)\n",
    "        agent_motions.append(agent_motion)\n",
    "        (A_new, K_new) = enviroment((A_new, agent_motion, K_new))\n",
    "\n",
    "    model_life = tf.keras.Model((A, K), (A_new, K_new, agent_motions), name='one_life_experience')\n",
    "    return model_life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"one_life_experience\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_enviroment (InputLayer)  [(None, 10, 10, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " agent_nn (Functional)          (None, 4)            804         ['image_enviroment[0][0]',       \n",
      "                                                                  'Enviroment[0][0]',             \n",
      "                                                                  'Enviroment[1][0]',             \n",
      "                                                                  'Enviroment[2][0]',             \n",
      "                                                                  'Enviroment[3][0]']             \n",
      "                                                                                                  \n",
      " agent_position (InputLayer)    [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " Enviroment (Functional)        ((None, 10, 10, 2),  152         ['image_enviroment[0][0]',       \n",
      "                                 (None, 2))                       'agent_nn[0][0]',               \n",
      "                                                                  'agent_position[0][0]',         \n",
      "                                                                  'Enviroment[0][0]',             \n",
      "                                                                  'agent_nn[1][0]',               \n",
      "                                                                  'Enviroment[0][1]',             \n",
      "                                                                  'Enviroment[1][0]',             \n",
      "                                                                  'agent_nn[2][0]',               \n",
      "                                                                  'Enviroment[1][1]',             \n",
      "                                                                  'Enviroment[2][0]',             \n",
      "                                                                  'agent_nn[3][0]',               \n",
      "                                                                  'Enviroment[2][1]',             \n",
      "                                                                  'Enviroment[3][0]',             \n",
      "                                                                  'agent_nn[4][0]',               \n",
      "                                                                  'Enviroment[3][1]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 956\n",
      "Trainable params: 804\n",
      "Non-trainable params: 152\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "After motion:\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "Position: [[2. 1.]]\n",
      "Motions: [[[0. 1. 1. 1.]]\n",
      "\n",
      " [[1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 1. 1.]]\n",
      "\n",
      " [[1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# Create Random Training Data:\n",
    "position = np.array([[1,1]])\n",
    "target_position = np.array([[3,3]])\n",
    "\n",
    "image = np.zeros(shape=(L,W,2))\n",
    "image[position[:,0], position[:,1], 0] = 1                      # Place the agent in the image of the enviroment\n",
    "image[target_position[:,0], target_position[:,1], 1] = 1        # Place the target in the image of the enviroment\n",
    "image = tf.constant([image])\n",
    "\n",
    "\n",
    "# Create Model in order to training an agent:\n",
    "agent_nn = get_agent_model()\n",
    "model_life = get_life_model(agent_nn, 5)\n",
    "model_life.summary()\n",
    "model_life.predict((image, position))\n",
    "\n",
    "# print('Before motion:')\n",
    "# print(np.swapaxes(np.squeeze(image), 0, 2))\n",
    "# print('Position:', position)\n",
    "\n",
    "print('\\nAfter motion:')\n",
    "# print(np.squeeze(model_life.predict((image, position))[0]))\n",
    "print(np.swapaxes(np.squeeze(model_life.predict((image, position))[0]), 0, 2))\n",
    "print('Position:', model_life.predict((image, position))[1])\n",
    "print('Motions:', np.array(model_life.predict((image, position))[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def life(agent, days_in_life):\n",
    "    random_target_positions = tf.random.constant()\n",
    "    test_random_target_positions = tf.random.constant()\n",
    "    model_life = get_life_model(agent.model)\n",
    "    model_life.fit(random_target_positions, random_target_positions, epochs=days_in_life)\n",
    "    \n",
    "    return model_life.evaluate(test_random_target_positions)[index_of_the_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(generations):\n",
    "    # Train for T epochs corresponding to the experience of one life-time\n",
    "    \n",
    "    for i, agent in population.agents:\n",
    "        fitness_scores[i] = life(agent, days_in_life=days_in_life)\n",
    "\n",
    "\n",
    "    # The 50'th best (closest) agents get to repopulate and cross mutate\n",
    "    # Crossmutation: Split tensors of model's weights and concat slices of two different agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('evo_comp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "293cb0476db60aaab2e1b1ba9b26f5f15c0ffb3fa3e660addecd3d738cf07a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
